{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargar el dataset y configurarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Descarga del dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "url = 'http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data'\n",
    "df = pd.read_csv(url, sep='\\t', header=0)\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "istrain_str = df['train']\n",
    "istrain = np.asarray([True if s == 'T' else False for s in istrain_str])\n",
    "istest = np.logical_not(istrain)\n",
    "df = df.drop('train', axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled['lpsa'] = df['lpsa']\n",
    "\n",
    "X = df_scaled.ix[:,:-1] #se le elimina la columna del target\n",
    "N = X.shape[0]\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N))\n",
    "y = df_scaled['lpsa'] #columna target\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "Xtest = X[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A)\n",
    "\n",
    "# En la tercera linea se saca la columna \"intercept\", puesto que ya no se necesita.\n",
    "# En la novena linea se ejecuta el metodo de Ridge a traves de factorizacion svd\n",
    "# con el parametro fit_intercept igual a True, puesto que el mismo metodo se encarga del intercepto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pylab as plt\n",
    "X = X.drop('intercept', axis=1)\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "names_regressors = [\"Lcavol\", \"Lweight\", \"Age\", \"Lbph\", \"Svi\", \"Lcp\", \"Gleason\", \"Pgg45\"]\n",
    "alphas_ = np.logspace(4,-1,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True,solver='svd')\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    coefs.append(model.coef_)\n",
    "ax = plt.gca()\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors): #que hace aca?\n",
    "    print alphas_.shape\n",
    "    print y_arr.shape\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "plt.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1]) # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Regularization Path RIDGE')\n",
    "plt.axis('tight')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelo lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "names_regressors = [\"Lcavol\", \"Lweight\", \"Age\", \"Lbph\", \"Svi\", \"Lcp\", \"Gleason\", \"Pgg45\"]\n",
    "alphas_ = np.logspace(1,-2,base=10)\n",
    "coefs = []\n",
    "model = Lasso(fit_intercept=True)\n",
    "for a in alphas_:\n",
    "\tmodel.set_params(alpha=a)\n",
    "\tmodel.fit(Xtrain, ytrain)\n",
    "\tcoefs.append(model.coef_)\n",
    "ax = plt.gca()\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "\tprint alphas_.shape\n",
    "\tprint y_arr.shape\n",
    "\tplt.plot(alphas_, y_arr, label=label)\n",
    "plt.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1]) # reverse axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Regularization Path LASSO')\n",
    "plt.axis('tight')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha y los errores en modelo ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest = X[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "alphas_ = np.logspace(2,-2,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True)\n",
    "mse_test = []\n",
    "mse_train = []\n",
    "for a in alphas_:\n",
    "\tmodel.set_params(alpha=a)\n",
    "\tmodel.fit(Xtrain, ytrain)\n",
    "\tyhat_train = model.predict(Xtrain)\n",
    "\tyhat_test = model.predict(Xtest)\n",
    "\tmse_train.append(np.mean(np.power(yhat_train - ytrain, 2)))\n",
    "\tmse_test.append(np.mean(np.power(yhat_test - ytest, 2)))\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas_,mse_train,label='train error Ridge')\n",
    "ax.plot(alphas_,mse_test,label='test error Ridge')\n",
    "plt.legend(loc=2)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha y errores en modelo lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtest = X[np.logical_not(istrain)]\n",
    "ytest = y[np.logical_not(istrain)]\n",
    "alphas_ = np.logspace(0.5,2,base=10)\n",
    "coefs = []\n",
    "model = Lasso(fit_intercept=True)\n",
    "mse_test = []\n",
    "mse_train = []\n",
    "for a in alphas_:\n",
    "\tmodel.set_params(alpha=a)\n",
    "\tmodel.fit(Xtrain, ytrain)\n",
    "\tyhat_train = model.predict(Xtrain)\n",
    "\tyhat_test = model.predict(Xtest)\n",
    "\tmse_train.append(np.mean(np.power(yhat_train - ytrain, 2)))\n",
    "\tmse_test.append(np.mean(np.power(yhat_test - ytest, 2)))\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas_,mse_train,label='train error Lasso')\n",
    "ax.plot(alphas_,mse_test,label='test error Lasso')\n",
    "plt.legend(loc=2)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mejor parametro alpha para cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para Ridge:\n",
      "BEST PARAMETER=100.000000, MSE(CV)=0.999646\n",
      "BEST PARAMETER=82.864277, MSE(CV)=0.965780\n",
      "BEST PARAMETER=68.664885, MSE(CV)=0.935286\n",
      "BEST PARAMETER=56.898660, MSE(CV)=0.908007\n",
      "BEST PARAMETER=47.148664, MSE(CV)=0.883727\n",
      "BEST PARAMETER=39.069399, MSE(CV)=0.862205\n",
      "BEST PARAMETER=32.374575, MSE(CV)=0.843206\n",
      "BEST PARAMETER=26.826958, MSE(CV)=0.826516\n",
      "BEST PARAMETER=22.229965, MSE(CV)=0.811949\n",
      "BEST PARAMETER=18.420700, MSE(CV)=0.799351\n",
      "BEST PARAMETER=15.264180, MSE(CV)=0.788588\n",
      "BEST PARAMETER=12.648552, MSE(CV)=0.779537\n",
      "BEST PARAMETER=10.481131, MSE(CV)=0.772077\n",
      "BEST PARAMETER=8.685114, MSE(CV)=0.766076\n",
      "BEST PARAMETER=7.196857, MSE(CV)=0.761390\n",
      "BEST PARAMETER=5.963623, MSE(CV)=0.757863\n",
      "BEST PARAMETER=4.941713, MSE(CV)=0.755328\n",
      "BEST PARAMETER=4.094915, MSE(CV)=0.753618\n",
      "BEST PARAMETER=3.393222, MSE(CV)=0.752571\n",
      "BEST PARAMETER=2.811769, MSE(CV)=0.752036\n",
      "BEST PARAMETER=2.329952, MSE(CV)=0.751881\n",
      "para Lasso:\n",
      "BEST PARAMETER=3.162278, MSE(CV)=1.795596\n",
      "BEST PARAMETER=0.954095, MSE(CV)=1.791936\n",
      "BEST PARAMETER=0.889159, MSE(CV)=1.769032\n",
      "BEST PARAMETER=0.828643, MSE(CV)=1.732198\n",
      "BEST PARAMETER=0.772245, MSE(CV)=1.701616\n",
      "BEST PARAMETER=0.719686, MSE(CV)=1.670821\n",
      "BEST PARAMETER=0.670704, MSE(CV)=1.619727\n",
      "BEST PARAMETER=0.625055, MSE(CV)=1.575554\n",
      "BEST PARAMETER=0.582514, MSE(CV)=1.534801\n",
      "BEST PARAMETER=0.542868, MSE(CV)=1.485163\n",
      "BEST PARAMETER=0.505920, MSE(CV)=1.424884\n",
      "BEST PARAMETER=0.471487, MSE(CV)=1.371576\n",
      "BEST PARAMETER=0.439397, MSE(CV)=1.319698\n",
      "BEST PARAMETER=0.409492, MSE(CV)=1.271762\n",
      "BEST PARAMETER=0.381621, MSE(CV)=1.230129\n",
      "BEST PARAMETER=0.355648, MSE(CV)=1.193370\n",
      "BEST PARAMETER=0.331442, MSE(CV)=1.160909\n",
      "BEST PARAMETER=0.308884, MSE(CV)=1.125800\n",
      "BEST PARAMETER=0.287862, MSE(CV)=1.095154\n",
      "BEST PARAMETER=0.268270, MSE(CV)=1.067204\n",
      "BEST PARAMETER=0.250011, MSE(CV)=1.043043\n",
      "BEST PARAMETER=0.232995, MSE(CV)=1.022392\n",
      "BEST PARAMETER=0.217137, MSE(CV)=1.003979\n",
      "BEST PARAMETER=0.202359, MSE(CV)=0.987634\n",
      "BEST PARAMETER=0.188586, MSE(CV)=0.972845\n",
      "BEST PARAMETER=0.175751, MSE(CV)=0.958748\n",
      "BEST PARAMETER=0.163789, MSE(CV)=0.945357\n",
      "BEST PARAMETER=0.152642, MSE(CV)=0.933008\n",
      "BEST PARAMETER=0.142253, MSE(CV)=0.922076\n",
      "BEST PARAMETER=0.132571, MSE(CV)=0.911942\n",
      "BEST PARAMETER=0.123548, MSE(CV)=0.901443\n",
      "BEST PARAMETER=0.115140, MSE(CV)=0.890003\n",
      "BEST PARAMETER=0.107303, MSE(CV)=0.879242\n",
      "BEST PARAMETER=0.100000, MSE(CV)=0.869968\n"
     ]
    }
   ],
   "source": [
    "def MSE(y,yhat): return np.mean(np.power(y-yhat,2))\n",
    "\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "\n",
    "def best_alpha(alphas_, Xm,ym, model):\n",
    "    k_fold = cross_validation.KFold(len(Xm),10)\n",
    "    best_cv_mse = float(\"inf\")\n",
    "    for a in alphas_:\n",
    "        model.set_params(alpha=a)\n",
    "        mse_list_k10 = [MSE(model.fit(Xm[train], ym[train]).predict(Xm[val]), ym[val]) for train, val in k_fold]\n",
    "        if np.mean(mse_list_k10) < best_cv_mse:\n",
    "            best_cv_mse = np.mean(mse_list_k10)\n",
    "            best_alpha = a\n",
    "            print \"BEST PARAMETER=%f, MSE(CV)=%f\"%(best_alpha,best_cv_mse) #para visualizar lo que sucede\n",
    "\n",
    "alphas_ridge = np.logspace( 2 ,-2  , base=10) \n",
    "alphas_lasso = np.logspace( 0.5 , -1, base = 10)\n",
    "\n",
    "#ejecucion\n",
    "print \"para Ridge:\"\n",
    "best_alpha(alphas_ridge,Xm,ym, Ridge(fit_intercept=True))\n",
    "print \"para Lasso:\"\n",
    "best_alpha(alphas_lasso,Xm,ym, Lasso(fit_intercept=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
